import faiss
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer

# **è¼‰å…¥èªæ„æ¨¡å‹**
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2', device='cuda')

# **è®€å– FAISS ç´¢å¼•**
index = faiss.read_index("faiss_index_ivf_new.bin")

# **è®€å–è©•è«–æ•¸æ“š**
df_comments = pd.read_csv("cleaned_comments_new.csv", usecols=["review_id", "location_id", "comments", "language"])

# **è®€å–åœ°é»è³‡è¨Š**
df_info = pd.read_json("E_838_location_info.json")
df_info = df_info.rename(columns={"location_id": "location_id", "gmap_location": "gmap_location"})

# **è®€å– FAISS review_id å°æ‡‰**
review_ids = np.load("review_ids_new.npy")  # FAISS å°æ‡‰çš„ review_id


def retrieve_similar_places(locations, semantic_keywords):
    """
    é‡å° `locations` æ¸…å–®ï¼Œä½¿ç”¨ `semantic_keywords` é€²è¡Œ FAISS æª¢ç´¢ï¼Œç¢ºä¿ `gmap_location` åªå‡ºç¾ä¸€æ¬¡ï¼Œä¸¦è¿”å›æœ€å¤š 5 å‰‡è©•è«–ã€‚
    """
    print("ğŸ“ FAISS æª¢ç´¢é–‹å§‹...")
    print(f"ğŸ—º é™åˆ¶æª¢ç´¢çš„åœ°é»æ•¸é‡: {len(locations)}")
    print(f"ğŸ”‘ ä½¿ç”¨èªæ„é—œéµè©: {semantic_keywords}")

    if not locations or not semantic_keywords:
        print("ğŸš¨ æ²’æœ‰åœ°é»æˆ–èªæ„é—œéµå­—ï¼Œè·³é FAISS æª¢ç´¢ã€‚")
        return []

    selected_locations = [loc["location_id"] for loc in locations]

    # **ç¯©é¸ç¬¦åˆçš„è©•è«–**
    filtered_comments = df_comments[df_comments["location_id"].isin(selected_locations)]
    print(f"ğŸ” ç¬¦åˆæ¢ä»¶çš„è©•è«–æ•¸é‡: {len(filtered_comments)}")

    if filtered_comments.empty:
        print("ğŸš¨ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è©•è«–ï¼ŒFAISS è·³éï¼")
        return []

    # **å‘é‡åŒ– `semantic_keywords`**
    query_vector = model.encode([" ".join(semantic_keywords)]).astype('float32')

    # **æé«˜ `k` å€¼ï¼Œè®“ FAISS å¯ä»¥è¿”å›æ›´å¤šè©•è«–**
    k = min(300, len(filtered_comments))
    distances, indices = index.search(query_vector, k)

    # **ç¯©é¸æœ‰æ•ˆçš„ç´¢å¼•**
    valid_mask = indices[0] >= 0  # éæ¿¾æ‰ -1
    valid_indices = indices[0][valid_mask]
    
    # **å¦‚æœæ²’æœ‰æœ‰æ•ˆç´¢å¼•ï¼Œç›´æ¥è¿”å›**
    if len(valid_indices) == 0:
        print("ğŸš¨ FAISS æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„è©•è«–ã€‚")
        return []
    
    valid_distances = distances[0][valid_mask]

    # **ä½¿ç”¨ review_id ä¾†ç¢ºä¿ç´¢å¼•å°æ‡‰**
    retrieved_review_ids = [review_ids[i] for i in valid_indices]

    # **ç¯©é¸ç¬¦åˆçš„è©•è«–**
    similar_reviews = filtered_comments[filtered_comments["review_id"].isin(retrieved_review_ids)].copy()

    # **åˆä½µåœ°é»åç¨±**
    df_merged = similar_reviews.merge(df_info[['location_id', 'gmap_location', 'address', 'summary_2']], on='location_id', how='left')

    # **ç¢ºä¿ `distances` å’Œ `df_merged` è¡Œæ•¸ä¸€è‡´**
    valid_distances = valid_distances[: len(df_merged)]
    df_merged["similarity_score"] = 1 / (1 + valid_distances)

    # **æ‡‰ç”¨ Softmax åŠ æ¬Š**
    alpha = 5
    exp_scores = np.exp(df_merged["similarity_score"] * alpha)
    df_merged["weight"] = exp_scores / exp_scores.sum()

    # **çµ±è¨ˆåœ°é»çš„åŠ æ¬Šåˆ†æ•¸**
    location_scores = df_merged.groupby(["gmap_location", "location_id", "address", "summary_2"])["weight"].sum().reset_index()
    location_scores = location_scores.sort_values(by="weight", ascending=False)

    # **ç¢ºä¿æ¯å€‹åœ°é»æœ€å¤šè¿”å› 5 å‰‡è©•è«–**
    grouped_reviews = df_merged.groupby("gmap_location").apply(lambda x: x.head(5)).reset_index(drop=True)

    # **å›å‚³çµæœ**
    results = []
    for idx, row in location_scores.head(10).iterrows():
        matched_reviews = grouped_reviews[grouped_reviews["gmap_location"] == row["gmap_location"]]

        results.append({
            "location_id": row["location_id"],
            "gmap_location": row["gmap_location"],
            "address": row["address"],
            "summary_2": row["summary_2"],
            "comments": matched_reviews["comments"].tolist(),  # å–æœ€å¤š 5 å‰‡è©•è«–
            "weight": row["weight"]
        })

    return results



if __name__ == "__main__":
    # **æ¸¬è©¦ FAISS æª¢ç´¢**
    test_locations = []
    test_keywords = []

    print("\nğŸ” æ¸¬è©¦ FAISS èªæ„æª¢ç´¢...")
    faiss_results = retrieve_similar_places(test_locations, test_keywords)

    if faiss_results:
        print("\nâœ… FAISS æª¢ç´¢çµæœï¼ˆæœ€å¤š 10 æ¢ï¼‰ï¼š")
        for idx, row in enumerate(faiss_results):
            print(f"{idx+1}. ğŸ“ {row['gmap_location']}")
            print(f"   ğŸ’¬ {row['comments']}")
            print(f"   âš–ï¸  ç›¸ä¼¼åº¦æ¬Šé‡: {row['weight']:.4f}")
            print("-" * 60)
    else:
        print("âŒ æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„è©•è«–ã€‚")
