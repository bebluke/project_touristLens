{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          zh        en        th        vi        id        ja        ko\n",
      "zh  1.000000  0.976558  0.972206  0.976441  0.971740  0.975853  0.971023\n",
      "en  0.976558  1.000000  0.971588  0.974763  0.975061  0.949565  0.941138\n",
      "th  0.972206  0.971588  1.000000  0.952332  0.954965  0.953862  0.939098\n",
      "vi  0.976441  0.974763  0.952332  1.000000  0.990144  0.974191  0.949870\n",
      "id  0.971740  0.975061  0.954965  0.990144  1.000000  0.971646  0.948115\n",
      "ja  0.975853  0.949565  0.953862  0.974191  0.971646  1.000000  0.967889\n",
      "ko  0.971023  0.941138  0.939098  0.949870  0.948115  0.967889  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. è¼‰å…¥ XLM-RoBERTaï¼ˆè·¨èªè¨€èªæ„æ¨¡å‹ï¼‰\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# 2. å‡è¨­é€™äº›æ˜¯ä¸åŒèªè¨€çš„è©•è«–\n",
    "comments = {\n",
    "    \"zh\": \"é€™å€‹åœ°æ–¹çœŸçš„å¾ˆç¾ï¼é©åˆæ”¾é¬†\",\n",
    "    \"en\": \"This place is really beautiful! Perfect for relaxing.\",\n",
    "    \"th\": \"à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ªà¸§à¸¢à¸‡à¸²à¸¡à¸¡à¸²à¸ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸œà¹ˆà¸­à¸™à¸„à¸¥à¸²à¸¢\",\n",
    "    \"vi\": \"NÆ¡i nÃ y thá»±c sá»± Ä‘áº¹p! HoÃ n háº£o Ä‘á»ƒ thÆ° giÃ£n.\",\n",
    "    \"id\": \"Tempat ini sangat indah! Sempurna untuk bersantai.\",\n",
    "    \"ja\":\"ã“ã“ã¯æœ¬å½“ã«ç¾ã—ã„ã§ã™ã­ï¼ãƒªãƒ©ãƒƒã‚¯ã‚¹ã«æœ€é©\",\n",
    "    \"ko\":\"ì´ê³³ì€ ì •ë§ ì•„ë¦„ë‹¤ì›Œìš”! íœ´ì‹ì— ì¢‹ë‹¤\"\n",
    "}\n",
    "\n",
    "# 3. å‘é‡åŒ–\n",
    "vectors = {lang: model.encode(text) for lang, text in comments.items()}\n",
    "\n",
    "# 4. è¨ˆç®—èªæ„ç›¸ä¼¼åº¦\n",
    "similarity_matrix = cosine_similarity(np.array(list(vectors.values())))\n",
    "\n",
    "# 5. è½‰æ›ç‚ºå¯è®€è¡¨æ ¼\n",
    "import pandas as pd\n",
    "langs = list(comments.keys())\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=langs, columns=langs)\n",
    "\n",
    "# é¡¯ç¤º DataFrame\n",
    "print(df_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          zh        iw        pl        cs\n",
      "zh  1.000000  0.893912  0.878800  0.874920\n",
      "iw  0.893912  1.000000  0.994681  0.991742\n",
      "pl  0.878800  0.994681  1.000000  0.993568\n",
      "cs  0.874920  0.991742  0.993568  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. è¼‰å…¥ XLM-RoBERTaï¼ˆè·¨èªè¨€èªæ„æ¨¡å‹ï¼‰\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# 2. å‡è¨­é€™äº›æ˜¯ä¸åŒèªè¨€çš„è©•è«–\n",
    "comments = {\n",
    "    \"zh\": \"é€™å€‹åœ°æ–¹çœŸçš„å¾ˆç¾ï¼é©åˆæ”¾é¬†\",\n",
    "    \"iw\": \"×–×”×• ××§×•× ×™×¤×” ×××•×“!\",  # å¸Œä¼¯ä¾†æ–‡\n",
    "    \"pl\": \"To bardzo piÄ™kne miejsce!\",  # æ³¢è˜­æ–‡\n",
    "    \"cs\": \"To je opravdu krÃ¡snÃ© mÃ­sto!\"  # æ·å…‹æ–‡\n",
    "}\n",
    "\n",
    "# 3. å‘é‡åŒ–\n",
    "vectors = {lang: model.encode(text) for lang, text in comments.items()}\n",
    "\n",
    "# 4. è¨ˆç®—èªæ„ç›¸ä¼¼åº¦\n",
    "similarity_matrix = cosine_similarity(np.array(list(vectors.values())))\n",
    "\n",
    "# 5. è½‰æ›ç‚ºå¯è®€è¡¨æ ¼\n",
    "import pandas as pd\n",
    "langs = list(comments.keys())\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=langs, columns=langs)\n",
    "\n",
    "# é¡¯ç¤º DataFrame\n",
    "print(df_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. è¼‰å…¥ XLM-RoBERTaï¼ˆè·¨èªè¨€èªæ„æ¨¡å‹ï¼‰\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# 2. å‡è¨­é€™äº›æ˜¯ä¸åŒèªè¨€çš„è©•è«–\n",
    "comments = {\n",
    "    \"zh\": \"é€™å€‹åœ°æ–¹çœŸçš„å¾ˆç¾ï¼é©åˆæ”¾é¬†\",\n",
    "    \"en\": \"This place is really beautiful! Perfect for relaxing.\",\n",
    "    \"th\": \"à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ªà¸§à¸¢à¸‡à¸²à¸¡à¸¡à¸²à¸ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸œà¹ˆà¸­à¸™à¸„à¸¥à¸²à¸¢\",\n",
    "    \"vi\": \"NÆ¡i nÃ y thá»±c sá»± Ä‘áº¹p! HoÃ n háº£o Ä‘á»ƒ thÆ° giÃ£n.\",\n",
    "    \"id\": \"Tempat ini sangat indah! Sempurna untuk bersantai.\",\n",
    "    \"ja\":\"ã“ã“ã¯æœ¬å½“ã«ç¾ã—ã„ã§ã™ã­ï¼ãƒªãƒ©ãƒƒã‚¯ã‚¹ã«æœ€é©\",\n",
    "    \"ko\":\"ì´ê³³ì€ ì •ë§ ì•„ë¦„ë‹¤ì›Œìš”! íœ´ì‹ì— ì¢‹ë‹¤\"\n",
    "}\n",
    "\n",
    "# 3. å‘é‡åŒ–\n",
    "vectors = {lang: model.encode(text) for lang, text in comments.items()}\n",
    "\n",
    "# 4. è¨ˆç®—èªæ„ç›¸ä¼¼åº¦\n",
    "similarity_matrix = cosine_similarity(np.array(list(vectors.values())))\n",
    "\n",
    "# 5. è½‰æ›ç‚ºå¯è®€è¡¨æ ¼\n",
    "import pandas as pd\n",
    "langs = list(comments.keys())\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=langs, columns=langs)\n",
    "\n",
    "# é¡¯ç¤º DataFrame\n",
    "print(df_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<?, ?it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9995]\n",
      " [0.949 ]\n",
      " [0.9556]\n",
      " [0.939 ]\n",
      " [0.949 ]\n",
      " [0.934 ]\n",
      " [0.934 ]\n",
      " [0.9995]\n",
      " [0.951 ]\n",
      " [0.9414]\n",
      " [0.9233]\n",
      " [0.966 ]\n",
      " [0.966 ]\n",
      " [0.9995]\n",
      " [0.96  ]\n",
      " [0.9395]\n",
      " [0.9478]\n",
      " [0.9478]\n",
      " [1.    ]\n",
      " [0.9272]\n",
      " [0.9346]\n",
      " [0.9346]\n",
      " [1.    ]\n",
      " [0.9062]\n",
      " [0.9062]\n",
      " [0.9995]\n",
      " [0.9995]\n",
      " [0.9995]]\n"
     ]
    }
   ],
   "source": [
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True, use_cuda=True, device=0)\n",
    "\n",
    "sentences_1 = [\"é€™å€‹åœ°æ–¹çœŸçš„å¾ˆç¾ï¼é©åˆæ”¾é¬†\"] #ä¸­æ–‡\n",
    "sentences_2 = [\"This place is really beautiful! Perfect for relaxing.\"] #è‹±æ–‡\n",
    "sentences_3 = [\"ã“ã“ã¯æœ¬å½“ã«ç¾ã—ã„ã§ã™ã­ï¼ãƒªãƒ©ãƒƒã‚¯ã‚¹ã«æœ€é©\"] #æ—¥æ–‡\n",
    "sentences_4 = [\"ì´ê³³ì€ ì •ë§ ì•„ë¦„ë‹¤ì›Œìš”! íœ´ì‹ì— ì¢‹ë‹¤\"] #éŸ“æ–‡\n",
    "sentences_5 = [\"à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆà¸™à¸µà¹‰à¸ªà¸§à¸¢à¸‡à¸²à¸¡à¸¡à¸²à¸ à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸œà¹ˆà¸­à¸™à¸„à¸¥à¸²à¸¢\"] #æ³°æ–‡\n",
    "sentences_6 = [\"NÆ¡i nÃ y thá»±c sá»± Ä‘áº¹p! HoÃ n háº£o Ä‘á»ƒ thÆ° giÃ£n.\"] #è¶Šå—æ–‡\n",
    "sentences_7 = [\"Tempat ini sangat indah! Sempurna untuk bersantai.\"] #å°å°¼æ–‡\n",
    "\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_2 = model.encode(sentences_2, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_3 = model.encode(sentences_3, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_4 = model.encode(sentences_4, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_5 = model.encode(sentences_5, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_6 = model.encode(sentences_6, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_7 = model.encode(sentences_6, batch_size=12, max_length=1024)['dense_vecs']\n",
    "\n",
    "similarity = np.vstack([\n",
    "    embeddings_1 @ embeddings_1.T,  \n",
    "    embeddings_1 @ embeddings_2.T,  \n",
    "    embeddings_1 @ embeddings_3.T,  \n",
    "    embeddings_1 @ embeddings_4.T,  \n",
    "    embeddings_1 @ embeddings_5.T,  \n",
    "    embeddings_1 @ embeddings_6.T,  \n",
    "    embeddings_1 @ embeddings_7.T,  \n",
    "    embeddings_2 @ embeddings_2.T,  \n",
    "    embeddings_2 @ embeddings_3.T,  \n",
    "    embeddings_2 @ embeddings_4.T,  \n",
    "    embeddings_2 @ embeddings_5.T,  \n",
    "    embeddings_2 @ embeddings_6.T,  \n",
    "    embeddings_2 @ embeddings_7.T,  \n",
    "    embeddings_3 @ embeddings_3.T,  \n",
    "    embeddings_3 @ embeddings_4.T,  \n",
    "    embeddings_3 @ embeddings_5.T, \n",
    "    embeddings_3 @ embeddings_6.T,  \n",
    "    embeddings_3 @ embeddings_7.T,  \n",
    "    embeddings_4 @ embeddings_4.T,  \n",
    "    embeddings_4 @ embeddings_5.T,  \n",
    "    embeddings_4 @ embeddings_6.T,  \n",
    "    embeddings_4 @ embeddings_7.T,  \n",
    "    embeddings_5 @ embeddings_5.T,  \n",
    "    embeddings_5 @ embeddings_6.T,  \n",
    "    embeddings_5 @ embeddings_7.T,  \n",
    "    embeddings_6 @ embeddings_6.T,   \n",
    "    embeddings_6 @ embeddings_7.T,   \n",
    "    embeddings_7 @ embeddings_7.T,   \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ—…éŠæª¢ç´¢æš¨æ¨è–¦ç³»çµ±ï¼ˆHybrid Search Systemï¼‰å·¥ä½œæµç¨‹\n",
    "\n",
    "## **1ï¸âƒ£ ä½¿ç”¨è€…è¼¸å…¥**\n",
    "- ä½¿ç”¨è€…è¼¸å…¥æŸ¥è©¢å…§å®¹ï¼ˆæ–‡å­— / åœ–ç‰‡ï¼‰ã€‚\n",
    "- æŸ¥è©¢å¯ä»¥æ˜¯é—œéµå­—ã€å®Œæ•´å¥å­ï¼Œæˆ–ä¸Šå‚³åœ–ç‰‡ã€‚\n",
    "\n",
    "## **2ï¸âƒ£ æŸ¥è©¢è§£æï¼ˆQuery Understandingï¼‰**\n",
    "- ä½¿ç”¨ **BERT / RoBERTa** åˆ¤æ–·æŸ¥è©¢é¡å‹ã€‚\n",
    "- **å»ºè­°æ¨¡å‹**ï¼š\n",
    "  - **mBERT (Multilingual BERT)**  \n",
    "    - **æ¨¡å‹ä¾†æº**ï¼š[Hugging Face Model Hub](https://huggingface.co/bert-base-multilingual-cased)\n",
    "  - **XLM-RoBERTa**  \n",
    "    - **æ¨¡å‹ä¾†æº**ï¼š[Hugging Face Model Hub](https://huggingface.co/xlm-roberta-base)\n",
    "- åˆ†ææŸ¥è©¢èªè¨€ï¼Œç¢ºå®šæ˜¯å¦éœ€è¦é€²è¡Œè·¨èªè¨€æª¢ç´¢ã€‚\n",
    "- **æŸ¥è©¢åˆ†é¡**ï¼š\n",
    "  - **é—œéµå­—æª¢ç´¢**ï¼ˆElasticSearchï¼‰\n",
    "  - **èªæ„æª¢ç´¢**ï¼ˆFAISSï¼‰\n",
    "  - **æ•¸å€¼ç¯©é¸**ï¼ˆç¥¨åƒ¹ã€åœç•™æ™‚é–“ï¼‰\n",
    "  - **å¤šæ¨¡æ…‹æŸ¥è©¢**ï¼ˆåœ–ç‰‡ â†’ æ–‡å­— â†’ FAISS æ¯”å°ï¼‰\n",
    "\n",
    "## **3ï¸âƒ£ æª¢ç´¢éšæ®µï¼ˆElasticSearch + FAISSï¼‰**\n",
    "- **é—œéµå­—æª¢ç´¢ï¼ˆElasticSearchï¼‰**ï¼šé©ç”¨æ–¼ç²¾ç¢ºåŒ¹é…ï¼ˆå¦‚åœ°é»åç¨±ã€æ¨™ç±¤ï¼‰ã€‚\n",
    "- **èªæ„æª¢ç´¢ï¼ˆFAISSï¼‰**ï¼šé€éèªæ„ç›¸ä¼¼åº¦è¨ˆç®—ï¼Œæ‰¾å‡ºæœ€ç›¸é—œçš„è©•è«–èˆ‡æ™¯é»ã€‚\n",
    "- **åœ–ç‰‡æª¢ç´¢ï¼ˆCLIP + FAISSï¼‰**ï¼š\n",
    "  - è‹¥ä½¿ç”¨è€…è¼¸å…¥åœ–ç‰‡ï¼Œå‰‡ä½¿ç”¨ **CLIP** è½‰æ›ç‚ºæ–‡å­—æè¿°ã€‚\n",
    "  - **å»ºè­°æ¨¡å‹**ï¼š\n",
    "    - **CLIP**ï¼š[openai/clip-vit-base-patch32](https://huggingface.co/openai/clip-vit-base-patch32)\n",
    "  - å†ä½¿ç”¨ FAISS é€²è¡Œèªæ„æ¯”å°ã€‚ã„Œ\n",
    "\n",
    "## **4ï¸âƒ£ å¤šèªè¨€æª¢ç´¢ï¼ˆèªè¨€ç›¸ä¼¼åº¦åˆ†æï¼‰**\n",
    "- **èªè¨€æ¨¡å‹é¸æ“‡**ï¼š\n",
    "  - **ä¸­æ–‡**ï¼š[sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)\n",
    "  - **è‹±æ–‡**ï¼š[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "  - **æ—¥æ–‡**ï¼š[cl-tohoku/bert-base-japanese](https://huggingface.co/cl-tohoku/bert-base-japanese)\n",
    "  - **éŸ“æ–‡**ï¼š[snunlp/KR-BERT](https://huggingface.co/snunlp/KR-BERT)\n",
    "  - **æ³°æ–‡**ï¼š[wangchanberta/wangchanberta-base-wiki](https://huggingface.co/airesearch/wangchanberta-base-wiki)\n",
    "  - **è¶Šå—æ–‡**ï¼š[vinai/phobert-base](https://huggingface.co/vinai/phobert-base)\n",
    "  - **å°å°¼æ–‡**ï¼š[indobenchmark/indobert-base-p1](https://huggingface.co/indobenchmark/indobert-base-p1)\n",
    "\n",
    "- **èªè¨€ç›¸ä¼¼åº¦åˆ†æ**ï¼š\n",
    "  - é€é **XLM-RoBERTa / LaBSE** è¨ˆç®—ä¸åŒèªè¨€çš„è©•è«–èªæ„ç›¸ä¼¼åº¦ã€‚\n",
    "  - è‹¥ç›¸ä¼¼åº¦é«˜ï¼ˆå¦‚ `sim(ko, th) > 0.85`ï¼‰ï¼Œå‰‡ **éŸ“æ–‡ / æ³°æ–‡è¼¸å…¥æ™‚åŒæ™‚æª¢ç´¢å…©è€…å‘é‡åº«**ã€‚\n",
    "- **èªè¨€å‹•æ…‹æª¢ç´¢ç­–ç•¥**ï¼š\n",
    "  - è‹¥æŸèªè¨€è©•è«–æ•¸é‡è¼ƒå°‘ï¼Œå‰‡æ“´å±•è‡³ç›¸ä¼¼èªè¨€çš„è©•è«–æ•¸æ“šã€‚\n",
    "  - ä¾‹å¦‚ï¼š\n",
    "    - **æ³°æ–‡è¼¸å…¥** â†’ ä¹Ÿæª¢ç´¢ **éŸ“æ–‡è©•è«–**\n",
    "    - **è¶Šå—æ–‡è¼¸å…¥** â†’ ä¹Ÿæª¢ç´¢ **è‹±æ–‡ + ç¹é«”ä¸­æ–‡è©•è«–**\n",
    "\n",
    "## **5ï¸âƒ£ ç†±é–€åº¦èª¿æ•´ï¼ˆPopularity Scoreï¼‰**\n",
    "- **è¿‘æœŸç†±é–€åº¦å½±éŸ¿æ’å**\n",
    "- ä½¿ç”¨è¿‘æœŸè©•è«–æ•¸ã€è©•åˆ†è®ŠåŒ–è¨ˆç®—ç†±é–€åº¦ï¼š\n",
    "  ```\n",
    "  Popularity Score = log(æœ€è¿‘30å¤©çš„è©•è«–æ•¸ + 1) * å¹³å‡è©•åˆ†\n",
    "  ```\n",
    "- **ç†±é–€æ™¯é»çš„å¾—åˆ†è¶Šé«˜ï¼Œæ’åè¶Šå‰**ã€‚\n",
    "\n",
    "## **6ï¸âƒ£ æ—…å®¢è¡Œç‚ºæ¨¡å¼ï¼ˆTraveler Behaviorï¼‰**\n",
    "- **ä¸åŒåœ‹ç±æ—…å®¢åå¥½ä¸åŒçš„æ™¯é»**ï¼š\n",
    "  - **éŸ“åœ‹æ—…å®¢** åå¥½ **æ–‡åŒ–æ™¯é»**ï¼ˆå¯ºå»Ÿã€å¤è¹Ÿï¼‰ã€‚\n",
    "  - **æ­ç¾æ—…å®¢** åå¥½ **è‡ªç„¶æ™¯é»**ï¼ˆå±±æ™¯ã€æµ·ç˜ï¼‰ã€‚\n",
    "- **æ ¹æ“šèªè¨€æ±ºå®šæ¨è–¦é¡å‹**\n",
    "  - **éŸ“æ–‡è¼¸å…¥** â†’ æé«˜æ–‡åŒ–æ™¯é»æ’åã€‚\n",
    "  - **è‹±æ–‡è¼¸å…¥** â†’ æé«˜è‡ªç„¶æ™¯é»æ’åã€‚\n",
    "\n",
    "## **7ï¸âƒ£ çµæœèåˆï¼ˆLTRæ’åºï¼‰**\n",
    "- **ç¶œåˆåŠ æ¬Šè¨ˆç®—æœ€çµ‚æ¨è–¦åˆ†æ•¸**ï¼š\n",
    "  ```\n",
    "  Final Score = Î± * èªæ„ç›¸ä¼¼åº¦ + Î² * ç†±é–€åº¦ + Î³ * æ—…å®¢è¡Œç‚º + Î´ * èªè¨€åŒ¹é…\n",
    "  ```\n",
    "- **ä½¿ç”¨ Learning-to-Rank (LTR) æ¨¡å‹é€²è¡Œæ’åº**ï¼Œç¢ºä¿æœ€ä½³æ¨è–¦çµæœã€‚\n",
    "\n",
    "## **8ï¸âƒ£ æ¨è–¦æ™¯é»**\n",
    "- æ ¹æ“š **LTR æ’åºçµæœ**ï¼Œè¼¸å‡º Top-N å€‹æ¨è–¦æ™¯é»ã€‚\n",
    "- æä¾› **æ™¯é»åç¨±ã€è©•åˆ†ã€ç†±é–€è©•è«–æ‘˜è¦**ã€‚\n",
    "\n",
    "## **ğŸ”¹ é€²åŒ–æ–¹å‘ï¼šå¾æª¢ç´¢ç³»çµ±åˆ°æ¨è–¦ç³»çµ±**\n",
    "| è®Šæ›´é …ç›® | æª¢ç´¢ç³»çµ± | æ¨è–¦ç³»çµ± |\n",
    "|------|------|------|\n",
    "| **æª¢ç´¢æ–¹å¼** | ä¾æ“šèªæ„ç›¸ä¼¼åº¦æŸ¥è©¢ | æ•´åˆèªæ„ç›¸ä¼¼åº¦ã€ç†±é–€åº¦ã€è¡Œç‚ºæ¨¡å¼ã€èªè¨€åˆ†æ |\n",
    "| **æ’åºæ©Ÿåˆ¶** | æŒ‰èªæ„ç›¸ä¼¼åº¦æ’åº | ä½¿ç”¨ LTR å‹•æ…‹èª¿æ•´æ¬Šé‡ |\n",
    "| **èªè¨€è™•ç†** | åªæŸ¥è©¢è¼¸å…¥èªè¨€ | è‹¥èªè¨€è©•è«–å°‘ï¼Œè‡ªå‹•æ“´å±•è‡³ç›¸ä¼¼èªè¨€ |\n",
    "| **æ—…å®¢è¡Œç‚ºå½±éŸ¿** | ç„¡ | æ ¹æ“šæ—…å®¢åœ‹ç±ã€èªè¨€èª¿æ•´æ¨è–¦çµæœ |\n",
    "\n",
    "**ğŸš€ ä¸‹ä¸€æ­¥ï¼š**\n",
    "1. **æ¸¬è©¦ä¸åŒåŠ æ¬Šç­–ç•¥ï¼ˆç†±é–€åº¦ vs. æ—…å®¢è¡Œç‚º vs. èªè¨€ç›¸ä¼¼åº¦ï¼‰**ã€‚\n",
    "2. **å¾®èª¿ LTR æ¨¡å‹ï¼Œç¢ºä¿æ’åºçµæœç¬¦åˆæ—…å®¢éœ€æ±‚**ã€‚\n",
    "\n",
    "é€™æ¨£ï¼Œæˆ‘å€‘çš„ç³»çµ±å·²ç¶“å¾ **ç´”æª¢ç´¢** è½‰è®Šç‚º **æ™ºèƒ½æ¨è–¦ç³»çµ±ï¼** ğŸ¯ğŸš€\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
