{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          zh        en        th        vi        id        ja        ko\n",
      "zh  1.000000  0.976558  0.972206  0.976441  0.971740  0.975853  0.971023\n",
      "en  0.976558  1.000000  0.971588  0.974763  0.975061  0.949565  0.941138\n",
      "th  0.972206  0.971588  1.000000  0.952332  0.954965  0.953862  0.939098\n",
      "vi  0.976441  0.974763  0.952332  1.000000  0.990144  0.974191  0.949870\n",
      "id  0.971740  0.975061  0.954965  0.990144  1.000000  0.971646  0.948115\n",
      "ja  0.975853  0.949565  0.953862  0.974191  0.971646  1.000000  0.967889\n",
      "ko  0.971023  0.941138  0.939098  0.949870  0.948115  0.967889  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. 載入 XLM-RoBERTa（跨語言語意模型）\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# 2. 假設這些是不同語言的評論\n",
    "comments = {\n",
    "    \"zh\": \"這個地方真的很美！適合放鬆\",\n",
    "    \"en\": \"This place is really beautiful! Perfect for relaxing.\",\n",
    "    \"th\": \"สถานที่นี้สวยงามมาก เหมาะสำหรับการผ่อนคลาย\",\n",
    "    \"vi\": \"Nơi này thực sự đẹp! Hoàn hảo để thư giãn.\",\n",
    "    \"id\": \"Tempat ini sangat indah! Sempurna untuk bersantai.\",\n",
    "    \"ja\":\"ここは本当に美しいですね！リラックスに最適\",\n",
    "    \"ko\":\"이곳은 정말 아름다워요! 휴식에 좋다\"\n",
    "}\n",
    "\n",
    "# 3. 向量化\n",
    "vectors = {lang: model.encode(text) for lang, text in comments.items()}\n",
    "\n",
    "# 4. 計算語意相似度\n",
    "similarity_matrix = cosine_similarity(np.array(list(vectors.values())))\n",
    "\n",
    "# 5. 轉換為可讀表格\n",
    "import pandas as pd\n",
    "langs = list(comments.keys())\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=langs, columns=langs)\n",
    "\n",
    "# 顯示 DataFrame\n",
    "print(df_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          zh        iw        pl        cs\n",
      "zh  1.000000  0.893912  0.878800  0.874920\n",
      "iw  0.893912  1.000000  0.994681  0.991742\n",
      "pl  0.878800  0.994681  1.000000  0.993568\n",
      "cs  0.874920  0.991742  0.993568  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. 載入 XLM-RoBERTa（跨語言語意模型）\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# 2. 假設這些是不同語言的評論\n",
    "comments = {\n",
    "    \"zh\": \"這個地方真的很美！適合放鬆\",\n",
    "    \"iw\": \"זהו מקום יפה מאוד!\",  # 希伯來文\n",
    "    \"pl\": \"To bardzo piękne miejsce!\",  # 波蘭文\n",
    "    \"cs\": \"To je opravdu krásné místo!\"  # 捷克文\n",
    "}\n",
    "\n",
    "# 3. 向量化\n",
    "vectors = {lang: model.encode(text) for lang, text in comments.items()}\n",
    "\n",
    "# 4. 計算語意相似度\n",
    "similarity_matrix = cosine_similarity(np.array(list(vectors.values())))\n",
    "\n",
    "# 5. 轉換為可讀表格\n",
    "import pandas as pd\n",
    "langs = list(comments.keys())\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=langs, columns=langs)\n",
    "\n",
    "# 顯示 DataFrame\n",
    "print(df_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. 載入 XLM-RoBERTa（跨語言語意模型）\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# 2. 假設這些是不同語言的評論\n",
    "comments = {\n",
    "    \"zh\": \"這個地方真的很美！適合放鬆\",\n",
    "    \"en\": \"This place is really beautiful! Perfect for relaxing.\",\n",
    "    \"th\": \"สถานที่นี้สวยงามมาก เหมาะสำหรับการผ่อนคลาย\",\n",
    "    \"vi\": \"Nơi này thực sự đẹp! Hoàn hảo để thư giãn.\",\n",
    "    \"id\": \"Tempat ini sangat indah! Sempurna untuk bersantai.\",\n",
    "    \"ja\":\"ここは本当に美しいですね！リラックスに最適\",\n",
    "    \"ko\":\"이곳은 정말 아름다워요! 휴식에 좋다\"\n",
    "}\n",
    "\n",
    "# 3. 向量化\n",
    "vectors = {lang: model.encode(text) for lang, text in comments.items()}\n",
    "\n",
    "# 4. 計算語意相似度\n",
    "similarity_matrix = cosine_similarity(np.array(list(vectors.values())))\n",
    "\n",
    "# 5. 轉換為可讀表格\n",
    "import pandas as pd\n",
    "langs = list(comments.keys())\n",
    "df_sim = pd.DataFrame(similarity_matrix, index=langs, columns=langs)\n",
    "\n",
    "# 顯示 DataFrame\n",
    "print(df_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<?, ?it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9995]\n",
      " [0.949 ]\n",
      " [0.9556]\n",
      " [0.939 ]\n",
      " [0.949 ]\n",
      " [0.934 ]\n",
      " [0.934 ]\n",
      " [0.9995]\n",
      " [0.951 ]\n",
      " [0.9414]\n",
      " [0.9233]\n",
      " [0.966 ]\n",
      " [0.966 ]\n",
      " [0.9995]\n",
      " [0.96  ]\n",
      " [0.9395]\n",
      " [0.9478]\n",
      " [0.9478]\n",
      " [1.    ]\n",
      " [0.9272]\n",
      " [0.9346]\n",
      " [0.9346]\n",
      " [1.    ]\n",
      " [0.9062]\n",
      " [0.9062]\n",
      " [0.9995]\n",
      " [0.9995]\n",
      " [0.9995]]\n"
     ]
    }
   ],
   "source": [
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True, use_cuda=True, device=0)\n",
    "\n",
    "sentences_1 = [\"這個地方真的很美！適合放鬆\"] #中文\n",
    "sentences_2 = [\"This place is really beautiful! Perfect for relaxing.\"] #英文\n",
    "sentences_3 = [\"ここは本当に美しいですね！リラックスに最適\"] #日文\n",
    "sentences_4 = [\"이곳은 정말 아름다워요! 휴식에 좋다\"] #韓文\n",
    "sentences_5 = [\"สถานที่นี้สวยงามมาก เหมาะสำหรับการผ่อนคลาย\"] #泰文\n",
    "sentences_6 = [\"Nơi này thực sự đẹp! Hoàn hảo để thư giãn.\"] #越南文\n",
    "sentences_7 = [\"Tempat ini sangat indah! Sempurna untuk bersantai.\"] #印尼文\n",
    "\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_2 = model.encode(sentences_2, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_3 = model.encode(sentences_3, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_4 = model.encode(sentences_4, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_5 = model.encode(sentences_5, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_6 = model.encode(sentences_6, batch_size=12, max_length=1024)['dense_vecs']\n",
    "embeddings_7 = model.encode(sentences_6, batch_size=12, max_length=1024)['dense_vecs']\n",
    "\n",
    "similarity = np.vstack([\n",
    "    embeddings_1 @ embeddings_1.T,  \n",
    "    embeddings_1 @ embeddings_2.T,  \n",
    "    embeddings_1 @ embeddings_3.T,  \n",
    "    embeddings_1 @ embeddings_4.T,  \n",
    "    embeddings_1 @ embeddings_5.T,  \n",
    "    embeddings_1 @ embeddings_6.T,  \n",
    "    embeddings_1 @ embeddings_7.T,  \n",
    "    embeddings_2 @ embeddings_2.T,  \n",
    "    embeddings_2 @ embeddings_3.T,  \n",
    "    embeddings_2 @ embeddings_4.T,  \n",
    "    embeddings_2 @ embeddings_5.T,  \n",
    "    embeddings_2 @ embeddings_6.T,  \n",
    "    embeddings_2 @ embeddings_7.T,  \n",
    "    embeddings_3 @ embeddings_3.T,  \n",
    "    embeddings_3 @ embeddings_4.T,  \n",
    "    embeddings_3 @ embeddings_5.T, \n",
    "    embeddings_3 @ embeddings_6.T,  \n",
    "    embeddings_3 @ embeddings_7.T,  \n",
    "    embeddings_4 @ embeddings_4.T,  \n",
    "    embeddings_4 @ embeddings_5.T,  \n",
    "    embeddings_4 @ embeddings_6.T,  \n",
    "    embeddings_4 @ embeddings_7.T,  \n",
    "    embeddings_5 @ embeddings_5.T,  \n",
    "    embeddings_5 @ embeddings_6.T,  \n",
    "    embeddings_5 @ embeddings_7.T,  \n",
    "    embeddings_6 @ embeddings_6.T,   \n",
    "    embeddings_6 @ embeddings_7.T,   \n",
    "    embeddings_7 @ embeddings_7.T,   \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 旅遊檢索暨推薦系統（Hybrid Search System）工作流程\n",
    "\n",
    "## **1️⃣ 使用者輸入**\n",
    "- 使用者輸入查詢內容（文字 / 圖片）。\n",
    "- 查詢可以是關鍵字、完整句子，或上傳圖片。\n",
    "\n",
    "## **2️⃣ 查詢解析（Query Understanding）**\n",
    "- 使用 **BERT / RoBERTa** 判斷查詢類型。\n",
    "- **建議模型**：\n",
    "  - **mBERT (Multilingual BERT)**  \n",
    "    - **模型來源**：[Hugging Face Model Hub](https://huggingface.co/bert-base-multilingual-cased)\n",
    "  - **XLM-RoBERTa**  \n",
    "    - **模型來源**：[Hugging Face Model Hub](https://huggingface.co/xlm-roberta-base)\n",
    "- 分析查詢語言，確定是否需要進行跨語言檢索。\n",
    "- **查詢分類**：\n",
    "  - **關鍵字檢索**（ElasticSearch）\n",
    "  - **語意檢索**（FAISS）\n",
    "  - **數值篩選**（票價、停留時間）\n",
    "  - **多模態查詢**（圖片 → 文字 → FAISS 比對）\n",
    "\n",
    "## **3️⃣ 檢索階段（ElasticSearch + FAISS）**\n",
    "- **關鍵字檢索（ElasticSearch）**：適用於精確匹配（如地點名稱、標籤）。\n",
    "- **語意檢索（FAISS）**：透過語意相似度計算，找出最相關的評論與景點。\n",
    "- **圖片檢索（CLIP + FAISS）**：\n",
    "  - 若使用者輸入圖片，則使用 **CLIP** 轉換為文字描述。\n",
    "  - **建議模型**：\n",
    "    - **CLIP**：[openai/clip-vit-base-patch32](https://huggingface.co/openai/clip-vit-base-patch32)\n",
    "  - 再使用 FAISS 進行語意比對。ㄌ\n",
    "\n",
    "## **4️⃣ 多語言檢索（語言相似度分析）**\n",
    "- **語言模型選擇**：\n",
    "  - **中文**：[sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)\n",
    "  - **英文**：[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "  - **日文**：[cl-tohoku/bert-base-japanese](https://huggingface.co/cl-tohoku/bert-base-japanese)\n",
    "  - **韓文**：[snunlp/KR-BERT](https://huggingface.co/snunlp/KR-BERT)\n",
    "  - **泰文**：[wangchanberta/wangchanberta-base-wiki](https://huggingface.co/airesearch/wangchanberta-base-wiki)\n",
    "  - **越南文**：[vinai/phobert-base](https://huggingface.co/vinai/phobert-base)\n",
    "  - **印尼文**：[indobenchmark/indobert-base-p1](https://huggingface.co/indobenchmark/indobert-base-p1)\n",
    "\n",
    "- **語言相似度分析**：\n",
    "  - 透過 **XLM-RoBERTa / LaBSE** 計算不同語言的評論語意相似度。\n",
    "  - 若相似度高（如 `sim(ko, th) > 0.85`），則 **韓文 / 泰文輸入時同時檢索兩者向量庫**。\n",
    "- **語言動態檢索策略**：\n",
    "  - 若某語言評論數量較少，則擴展至相似語言的評論數據。\n",
    "  - 例如：\n",
    "    - **泰文輸入** → 也檢索 **韓文評論**\n",
    "    - **越南文輸入** → 也檢索 **英文 + 繁體中文評論**\n",
    "\n",
    "## **5️⃣ 熱門度調整（Popularity Score）**\n",
    "- **近期熱門度影響排名**\n",
    "- 使用近期評論數、評分變化計算熱門度：\n",
    "  ```\n",
    "  Popularity Score = log(最近30天的評論數 + 1) * 平均評分\n",
    "  ```\n",
    "- **熱門景點的得分越高，排名越前**。\n",
    "\n",
    "## **6️⃣ 旅客行為模式（Traveler Behavior）**\n",
    "- **不同國籍旅客偏好不同的景點**：\n",
    "  - **韓國旅客** 偏好 **文化景點**（寺廟、古蹟）。\n",
    "  - **歐美旅客** 偏好 **自然景點**（山景、海灘）。\n",
    "- **根據語言決定推薦類型**\n",
    "  - **韓文輸入** → 提高文化景點排名。\n",
    "  - **英文輸入** → 提高自然景點排名。\n",
    "\n",
    "## **7️⃣ 結果融合（LTR排序）**\n",
    "- **綜合加權計算最終推薦分數**：\n",
    "  ```\n",
    "  Final Score = α * 語意相似度 + β * 熱門度 + γ * 旅客行為 + δ * 語言匹配\n",
    "  ```\n",
    "- **使用 Learning-to-Rank (LTR) 模型進行排序**，確保最佳推薦結果。\n",
    "\n",
    "## **8️⃣ 推薦景點**\n",
    "- 根據 **LTR 排序結果**，輸出 Top-N 個推薦景點。\n",
    "- 提供 **景點名稱、評分、熱門評論摘要**。\n",
    "\n",
    "## **🔹 進化方向：從檢索系統到推薦系統**\n",
    "| 變更項目 | 檢索系統 | 推薦系統 |\n",
    "|------|------|------|\n",
    "| **檢索方式** | 依據語意相似度查詢 | 整合語意相似度、熱門度、行為模式、語言分析 |\n",
    "| **排序機制** | 按語意相似度排序 | 使用 LTR 動態調整權重 |\n",
    "| **語言處理** | 只查詢輸入語言 | 若語言評論少，自動擴展至相似語言 |\n",
    "| **旅客行為影響** | 無 | 根據旅客國籍、語言調整推薦結果 |\n",
    "\n",
    "**🚀 下一步：**\n",
    "1. **測試不同加權策略（熱門度 vs. 旅客行為 vs. 語言相似度）**。\n",
    "2. **微調 LTR 模型，確保排序結果符合旅客需求**。\n",
    "\n",
    "這樣，我們的系統已經從 **純檢索** 轉變為 **智能推薦系統！** 🎯🚀\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
