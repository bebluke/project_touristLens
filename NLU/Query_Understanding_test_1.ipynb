{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Start training xlm-roberta-base =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 00:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357370</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>0.142302</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.971907</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.971910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.086564</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.983144</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.983146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set: {'eval_loss': 0.08656444400548935, 'eval_f1_micro': 0.9831460674157303, 'eval_f1_macro': 0.9831439393939394, 'eval_precision_micro': 0.9831460674157303, 'eval_recall_micro': 0.9831460674157303, 'eval_runtime': 0.3463, 'eval_samples_per_second': 256.967, 'eval_steps_per_second': 34.647, 'epoch': 3.0}\n",
      "=== Label: semantic_search ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     1.0000    1.0000    1.0000        89\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9828    1.0000    0.9913        57\n",
      "         1.0     1.0000    0.9688    0.9841        32\n",
      "\n",
      "    accuracy                         0.9888        89\n",
      "   macro avg     0.9914    0.9844    0.9877        89\n",
      "weighted avg     0.9890    0.9888    0.9887        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_distance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.9688    0.9841        32\n",
      "         1.0     0.9828    1.0000    0.9913        57\n",
      "\n",
      "    accuracy                         0.9888        89\n",
      "   macro avg     0.9914    0.9844    0.9877        89\n",
      "weighted avg     0.9890    0.9888    0.9887        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: numeric_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9551    1.0000    0.9770        85\n",
      "         1.0     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.9551        89\n",
      "   macro avg     0.4775    0.5000    0.4885        89\n",
      "weighted avg     0.9121    0.9551    0.9331        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Overall (flatten) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9719    0.9943    0.9830       174\n",
      "         1.0     0.9944    0.9725    0.9833       182\n",
      "\n",
      "    accuracy                         0.9831       356\n",
      "   macro avg     0.9831    0.9834    0.9831       356\n",
      "weighted avg     0.9834    0.9831    0.9831       356\n",
      "\n",
      "===== End training xlm-roberta-base =====\n",
      "\n",
      "===== Start training xlm-roberta-large =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 03:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.452666</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.195711</td>\n",
       "      <td>0.929775</td>\n",
       "      <td>0.929775</td>\n",
       "      <td>0.929775</td>\n",
       "      <td>0.929775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.050302</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.988763</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set: {'eval_loss': 0.05030224472284317, 'eval_f1_micro': 0.9887640449438202, 'eval_f1_macro': 0.9887626262626263, 'eval_precision_micro': 0.9887640449438202, 'eval_recall_micro': 0.9887640449438202, 'eval_runtime': 0.7274, 'eval_samples_per_second': 122.359, 'eval_steps_per_second': 16.498, 'epoch': 3.0}\n",
      "=== Label: semantic_search ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     1.0000    1.0000    1.0000        89\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        57\n",
      "         1.0     1.0000    1.0000    1.0000        32\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_distance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        32\n",
      "         1.0     1.0000    1.0000    1.0000        57\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: numeric_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9551    1.0000    0.9770        85\n",
      "         1.0     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.9551        89\n",
      "   macro avg     0.4775    0.5000    0.4885        89\n",
      "weighted avg     0.9121    0.9551    0.9331        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Overall (flatten) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9775    1.0000    0.9886       174\n",
      "         1.0     1.0000    0.9780    0.9889       182\n",
      "\n",
      "    accuracy                         0.9888       356\n",
      "   macro avg     0.9888    0.9890    0.9888       356\n",
      "weighted avg     0.9890    0.9888    0.9888       356\n",
      "\n",
      "===== End training xlm-roberta-large =====\n",
      "\n",
      "===== Start training bert-base-multilingual-cased =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 00:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082174</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.988763</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.045060</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>0.997191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.037839</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>0.997191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set: {'eval_loss': 0.045060351490974426, 'eval_f1_micro': 0.9971910112359551, 'eval_f1_macro': 0.9971899247752334, 'eval_precision_micro': 0.9971910112359551, 'eval_recall_micro': 0.9971910112359551, 'eval_runtime': 0.3879, 'eval_samples_per_second': 229.463, 'eval_steps_per_second': 30.939, 'epoch': 3.0}\n",
      "=== Label: semantic_search ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     1.0000    1.0000    1.0000        89\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        57\n",
      "         1.0     1.0000    1.0000    1.0000        32\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_distance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        32\n",
      "         1.0     1.0000    1.0000    1.0000        57\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: numeric_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9884    1.0000    0.9942        85\n",
      "         1.0     1.0000    0.7500    0.8571         4\n",
      "\n",
      "    accuracy                         0.9888        89\n",
      "   macro avg     0.9942    0.8750    0.9256        89\n",
      "weighted avg     0.9889    0.9888    0.9880        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Overall (flatten) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9943    1.0000    0.9971       174\n",
      "         1.0     1.0000    0.9945    0.9972       182\n",
      "\n",
      "    accuracy                         0.9972       356\n",
      "   macro avg     0.9971    0.9973    0.9972       356\n",
      "weighted avg     0.9972    0.9972    0.9972       356\n",
      "\n",
      "===== End training bert-base-multilingual-cased =====\n",
      "\n",
      "===== Start training sentence-transformers/paraphrase-multilingual-mpnet-base-v2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-multilingual-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 00:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255929</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.977525</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.977528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.422900</td>\n",
       "      <td>0.138501</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.983144</td>\n",
       "      <td>0.983146</td>\n",
       "      <td>0.983146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.109457</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.988763</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set: {'eval_loss': 0.10945658385753632, 'eval_f1_micro': 0.9887640449438202, 'eval_f1_macro': 0.9887626262626263, 'eval_precision_micro': 0.9887640449438202, 'eval_recall_micro': 0.9887640449438202, 'eval_runtime': 0.3495, 'eval_samples_per_second': 254.668, 'eval_steps_per_second': 34.337, 'epoch': 3.0}\n",
      "=== Label: semantic_search ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     1.0000    1.0000    1.0000        89\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        57\n",
      "         1.0     1.0000    1.0000    1.0000        32\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: geo_distance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        32\n",
      "         1.0     1.0000    1.0000    1.0000        57\n",
      "\n",
      "    accuracy                         1.0000        89\n",
      "   macro avg     1.0000    1.0000    1.0000        89\n",
      "weighted avg     1.0000    1.0000    1.0000        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Label: numeric_filter ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9551    1.0000    0.9770        85\n",
      "         1.0     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.9551        89\n",
      "   macro avg     0.4775    0.5000    0.4885        89\n",
      "weighted avg     0.9121    0.9551    0.9331        89\n",
      "\n",
      "-----------------------------------\n",
      "=== Overall (flatten) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9775    1.0000    0.9886       174\n",
      "         1.0     1.0000    0.9780    0.9889       182\n",
      "\n",
      "    accuracy                         0.9888       356\n",
      "   macro avg     0.9888    0.9890    0.9888       356\n",
      "weighted avg     0.9890    0.9888    0.9888       356\n",
      "\n",
      "===== End training sentence-transformers/paraphrase-multilingual-mpnet-base-v2 =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ALL_LABELS = [\"semantic_search\", \"geo_filter\", \"geo_distance\", \"numeric_filter\"]\n",
    "CSV_PATH = \"query_training_data_.csv\"  # ‰øÆÊ≠£Êàê‰Ω†Ëá™Â∑±ÁöÑ CSV\n",
    "\n",
    "def encode_labels(label_str):\n",
    "    label_list = label_str.split(\",\")\n",
    "    label_list = [l.strip() for l in label_list]\n",
    "    encoding = [1 if lbl in label_list else 0 for lbl in ALL_LABELS]\n",
    "    return encoding\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"encoded_labels\"] = df[\"Labels\"].apply(encode_labels)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "class QueryDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=64):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row[\"Query\"]\n",
    "        labels = row[\"encoded_labels\"]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "def multi_label_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = expit(logits)\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    preds_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    f1_micro = f1_score(labels_flat, preds_flat, average=\"micro\")\n",
    "    f1_macro = f1_score(labels_flat, preds_flat, average=\"macro\")\n",
    "    precision_micro = precision_score(labels_flat, preds_flat, average=\"micro\")\n",
    "    recall_micro = recall_score(labels_flat, preds_flat, average=\"micro\")\n",
    "\n",
    "    return {\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_micro\": precision_micro,\n",
    "        \"recall_micro\": recall_micro\n",
    "    }\n",
    "\n",
    "def evaluate_classification_report(trainer, dataset, all_labels):\n",
    "    preds_output = trainer.predict(dataset)\n",
    "    logits = preds_output.predictions\n",
    "    labs = preds_output.label_ids\n",
    "    probs = expit(logits)\n",
    "    pred_bin = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # (A) ÈÄêÂÄã label Â†±Âëä\n",
    "    for i, label_name in enumerate(all_labels):\n",
    "        y_true = labs[:, i]\n",
    "        y_pred = pred_bin[:, i]\n",
    "        print(f\"=== Label: {label_name} ===\")\n",
    "        print(classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            zero_division=0, digits=4\n",
    "        ))\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "    # (B) flatten ÂÅö overall Â†±Âëä\n",
    "    pred_flat = pred_bin.flatten()\n",
    "    labs_flat = labs.flatten()\n",
    "    print(\"=== Overall (flatten) ===\")\n",
    "    print(classification_report(\n",
    "        labs_flat,\n",
    "        pred_flat,\n",
    "        zero_division=0, digits=4\n",
    "    ))\n",
    "\n",
    "def train_and_evaluate_model(model_name, train_df, test_df):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    train_dataset = QueryDataset(train_df, tokenizer)\n",
    "    test_dataset = QueryDataset(test_df, tokenizer)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(ALL_LABELS)\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./outputs_{model_name.replace('/', '_')}\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_micro\",\n",
    "        greater_is_better=True,\n",
    "        logging_dir=f\"./logs_{model_name.replace('/', '_')}\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=multi_label_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Âú® test set ‰∏äÂÅöÊúÄÁµÇË©ï‰º∞ (Êï¥È´îÊï∏Êìö)\n",
    "    result = trainer.evaluate(test_dataset)\n",
    "    print(\"Evaluation on test set:\", result)\n",
    "\n",
    "    # Êõ¥Ë©≥Á¥∞ÈÄêÂÄã label Â†±Âëä\n",
    "    evaluate_classification_report(trainer, test_dataset, ALL_LABELS)\n",
    "\n",
    "# ÂèØÊõøÊèõÊ®°Âûã\n",
    "CANDIDATE_MODELS = [\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlm-roberta-large\",\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "]\n",
    "\n",
    "for model_name in CANDIDATE_MODELS:\n",
    "    print(f\"===== Start training {model_name} =====\")\n",
    "    train_and_evaluate_model(model_name, train_df, test_df)\n",
    "    print(f\"===== End training {model_name} =====\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ê∏¨Ë©¶ Query ÂàÜÈ°û"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰∏ãËºâ tokenizer ‰∏¶Â≠òÂÖ•: c:/Users/Administrator/Downloads/SCR/NLU\\outputs_xlm-roberta-base\\checkpoint-135\n",
      "‰∏ãËºâ tokenizer ‰∏¶Â≠òÂÖ•: c:/Users/Administrator/Downloads/SCR/NLU\\outputs_xlm-roberta-large\\checkpoint-135\n",
      "‰∏ãËºâ tokenizer ‰∏¶Â≠òÂÖ•: c:/Users/Administrator/Downloads/SCR/NLU\\outputs_bert-base-multilingual-cased\\checkpoint-135\n",
      "‰∏ãËºâ tokenizer ‰∏¶Â≠òÂÖ•: c:/Users/Administrator/Downloads/SCR/NLU\\outputs_sentence-transformers_paraphrase-multilingual-mpnet-base-v2\\checkpoint-135\n",
      "ÊâÄÊúâ tokenizer Ë£úÂÖ®\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ‰Ω†ÁöÑÂõõÂÄãÂÄôÈÅ∏Ê®°Âûã\n",
    "CANDIDATE_MODELS = [\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlm-roberta-large\",\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "]\n",
    "\n",
    "# Ë®≠ÂÆöÊ®°ÂûãÂ≠òÊîæÁöÑÂü∫Á§éË≥áÊñôÂ§æ\n",
    "BASE_DIR = \"c:/Users/Administrator/Downloads/SCR/NLU\"\n",
    "\n",
    "# ÈÅçÊ≠∑ÊØèÂÄãÊ®°ÂûãÔºå‰∏ãËºâ‰∏¶Â≠òÂÖ•Â∞çÊáâ checkpoint-135\n",
    "for model_name in CANDIDATE_MODELS:\n",
    "    model_dir = os.path.join(BASE_DIR, f\"outputs_{model_name.replace('/', '_')}\", \"checkpoint-135\")\n",
    "    \n",
    "    # Ê™¢Êü•Ë©≤ checkpoint ÊòØÂê¶Â≠òÂú®\n",
    "    if not os.path.isdir(model_dir):\n",
    "        print(f\"‚ö†Ô∏è {model_dir} ‰∏çÂ≠òÂú®ÔºåË∑≥ÈÅé...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"‰∏ãËºâ tokenizer ‰∏¶Â≠òÂÖ•: {model_dir}\")\n",
    "\n",
    "    # ‰∏ãËºâÂ∞çÊáâÁöÑ tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.save_pretrained(model_dir)  # Â≠òÂÖ• `checkpoint-135`\n",
    "\n",
    "print(\"ÊâÄÊúâ tokenizer Ë£úÂÖ®\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ê∏¨Ë©¶ Query: ÊàëÊÉ≥ÊâæÂú®ÈòøÈáåÂ±±ÈôÑËøëÁöÑÁâπËâ≤ÂíñÂï°Âª≥ÔºåÂèØ‰ª•ÁúãÂà∞Â±±ÊôØ\n",
      "[Model: xlm-roberta-base] Predictions:\n",
      "  semantic_search: True\n",
      "  geo_filter: False\n",
      "  geo_distance: True\n",
      "  numeric_filter: False\n",
      "-----------------------------------\n",
      "[Model: xlm-roberta-large] Predictions:\n",
      "  semantic_search: True\n",
      "  geo_filter: False\n",
      "  geo_distance: True\n",
      "  numeric_filter: False\n",
      "-----------------------------------\n",
      "[Model: bert-base-multilingual-cased] Predictions:\n",
      "  semantic_search: True\n",
      "  geo_filter: False\n",
      "  geo_distance: True\n",
      "  numeric_filter: False\n",
      "-----------------------------------\n",
      "[Model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2] Predictions:\n",
      "  semantic_search: True\n",
      "  geo_filter: False\n",
      "  geo_distance: True\n",
      "  numeric_filter: False\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import expit\n",
    "\n",
    "ALL_LABELS = [\"semantic_search\", \"geo_filter\", \"geo_distance\", \"numeric_filter\"]\n",
    "\n",
    "# ‰Ω†ÁöÑÊ®°ÂûãÂàóË°®\n",
    "CANDIDATE_MODELS = [\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlm-roberta-large\",\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def predict_with_model(model_dir, query_text):\n",
    "    \"\"\"\n",
    "    Âæû model_dir/checkpoint-135 ËºâÂÖ• safetensors Ê®°ÂûãÔºå‰∏¶Â∞ç query_text ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇ\n",
    "    \"\"\"\n",
    "    ckpt_path = os.path.join(model_dir, \"checkpoint-135\")  # Âõ∫ÂÆöËºâÂÖ• checkpoint-135\n",
    "    ckpt_path = os.path.abspath(ckpt_path)  # ËΩâÊèõÁÇ∫ÁµïÂ∞çË∑ØÂæë\n",
    "   \n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ckpt_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(ckpt_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize Ëº∏ÂÖ•\n",
    "    inputs = tokenizer(query_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.cpu().numpy()\n",
    "        probs = expit(logits)  # sigmoid\n",
    "        preds = (probs >= 0.5).astype(int).flatten()\n",
    "\n",
    "    return preds\n",
    "\n",
    "# Ê∏¨Ë©¶ Query\n",
    "test_query = \"ÊàëÊÉ≥ÊâæÂú®ÈòøÈáåÂ±±ÈôÑËøëÁöÑÁâπËâ≤ÂíñÂï°Âª≥ÔºåÂèØ‰ª•ÁúãÂà∞Â±±ÊôØ\"\n",
    "\n",
    "print(f\"Ê∏¨Ë©¶ Query: {test_query}\")\n",
    "for model_name in CANDIDATE_MODELS:\n",
    "    # ÊØèÂÄãÊ®°ÂûãÁöÑËº∏Âá∫ÁõÆÈåÑÔºå‰æãÂ¶Ç ./outputs_xlm-roberta-base\n",
    "    MODEL_DIR = f\"./outputs_{model_name.replace('/', '_')}\"\n",
    "    MODEL_DIR = os.path.abspath(MODEL_DIR)  # ËΩâÊàêÁµïÂ∞çË∑ØÂæë\n",
    "\n",
    "    # ‰ΩøÁî® checkpoint-135 ÂÅöÊé®ÁêÜ\n",
    "    preds = predict_with_model(MODEL_DIR, test_query)\n",
    "    \n",
    "    # Ëº∏Âá∫ÁµêÊûú\n",
    "    print(f\"[Model: {model_name}] Predictions:\")\n",
    "    for label, p in zip(ALL_LABELS, preds):\n",
    "        print(f\"  {label}: {bool(p)}\")\n",
    "    print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLU Ê®°ÂûãÊ∏¨Ë©¶ÁµêÊûúÂàÜÊûê\n",
    "\n",
    "## **ÊúÄ‰Ω≥Ê®°ÂûãÔºö`bert-base-multilingual-cased`**\n",
    "- `f1_micro = 0.9972` **(ÊúÄÈ´òÊ∫ñÁ¢∫Áéá)**\n",
    "- `eval_loss = 0.0451` **(ÊúÄ‰ΩéË™§Â∑Æ)**\n",
    "- `eval_runtime = 0.3879s` **(ÈÄüÂ∫¶ÈÅ©‰∏≠)**\n",
    "- **Êé®Ëñ¶‰ΩúÁÇ∫ NLU Ê®°ÂûãÔºåÊèê‰æõÊúÄÊ∫ñÁ¢∫ÁöÑÊ™¢Á¥¢ÂàÜÈ°ûÔºÅ**\n",
    "\n",
    "---\n",
    "\n",
    "## **ÂÖ∂‰ªñÊ®°ÂûãÊØîËºÉ**\n",
    "| Ê®°Âûã | `f1_micro` | `eval_loss` | `eval_runtime` |\n",
    "|------|------------|-------------|----------------|\n",
    "| **`bert-base-multilingual-cased`** ‚úÖ | **0.9972** | **0.0451** | **0.3879s** |\n",
    "| `xlm-roberta-large` | 0.9888 | 0.0503 | 0.7274s |\n",
    "| `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` üöÄ **(ÊúÄÂø´)** | 0.9888 | **ÊúÄÂ∑Æ 0.1094** | **ÊúÄÂø´ 0.3495s** |\n",
    "| `xlm-roberta-base` ‚ùå **(ÊúÄÂ∑Æ)** | 0.9831 | 0.0865 | 0.3463s |\n",
    "\n",
    "---\n",
    "\n",
    "## ** Âª∫Ë≠∞**\n",
    "-  **`bert-base-multilingual-cased`** **(ÊúÄÊ∫ñÁ¢∫ÔºåÊé®Ëñ¶‰ΩøÁî®)**\n",
    "-  **`sentence-transformers/paraphrase-multilingual-mpnet-base-v2`** **(Êé®ÁêÜÊúÄÂø´ÔºåÈÅ©ÂêàÈÄüÂ∫¶ÈúÄÊ±Ç)**\n",
    "-  **`xlm-roberta-base`** **(Ê∫ñÁ¢∫ÁéáÊúÄ‰ΩéÔºå‰∏çÂª∫Ë≠∞‰ΩøÁî®)**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
