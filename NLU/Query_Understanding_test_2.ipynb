{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Davlan/xlm-roberta-base-ner-hrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOCATION': ['阿里山'], 'ADDRESS': [], 'POI_TYPE': [], 'NEED': [], 'search_type': ['geo_filter']}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "def load_nlu_models():\n",
    "    \"\"\"載入 NER（XLM-RoBERTa）與 Query 分類（mT5）模型\"\"\"\n",
    "    # NER 模型（XLM-RoBERTa，使用新模型 Davlan/xlm-roberta-base-ner-hrl）\n",
    "    ner_model_name = \"Davlan/xlm-roberta-base-ner-hrl\"\n",
    "    ner_tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_name)\n",
    "    ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    # Query 類別分類（mT5）\n",
    "    query_model_name = \"google/mt5-small\"\n",
    "    query_tokenizer = T5Tokenizer.from_pretrained(query_model_name, model_max_length=512)\n",
    "    query_model = MT5ForConditionalGeneration.from_pretrained(query_model_name, device_map=\"auto\")\n",
    "    \n",
    "    return ner_pipeline, query_model, query_tokenizer\n",
    "\n",
    "def extract_entities(query, ner_pipeline):\n",
    "    \"\"\"使用 XLM-RoBERTa NER 模型來提取 LOCATION、POI_TYPE、NEED、ADDRESS，並合併子詞\"\"\"\n",
    "    entities = ner_pipeline(query)\n",
    "    \n",
    "    # 初始化結果\n",
    "    result = {\"LOCATION\": [], \"ADDRESS\": [], \"POI_TYPE\": [], \"NEED\": []}\n",
    "    label_map = {\"LOC\": \"LOCATION\", \"ORG\": \"POI_TYPE\", \"MISC\": \"NEED\"}\n",
    "    \n",
    "    prev_label, prev_word = None, \"\"\n",
    "    for entity in entities:\n",
    "        word = entity['word'].replace(\"▁\", \"\").strip()  # 去掉特殊符號並去除空格\n",
    "        label = entity['entity']  # BIO 格式標籤\n",
    "        main_label = label[2:] if \"-\" in label else label  # 移除 B- 或 I-，保留類別\n",
    "        mapped_label = label_map.get(main_label, None)  # 轉換成我們的分類\n",
    "        \n",
    "        if not mapped_label or not word:\n",
    "            continue  # 如果標籤不在我們的分類中或是空字串，跳過\n",
    "        \n",
    "        # BIO 轉換，將 B- 和 I- 合併處理\n",
    "        if label.startswith(\"B-\"):\n",
    "            if prev_label and prev_word.strip():\n",
    "                result[prev_label].append(prev_word)  # 存入前一個詞\n",
    "            prev_word = word\n",
    "            prev_label = mapped_label  # 存儲對應的標籤\n",
    "        elif label.startswith(\"I-\") and prev_label == mapped_label:\n",
    "            prev_word += word  # 合併詞\n",
    "        else:\n",
    "            if prev_label and prev_word.strip():\n",
    "                result[prev_label].append(prev_word)  # 存入前一個詞\n",
    "            prev_label, prev_word = None, \"\"\n",
    "    \n",
    "    if prev_label and prev_word.strip():\n",
    "        result[prev_label].append(prev_word)  # 存入最後一個詞\n",
    "    \n",
    "    # 如果 LOCATION 是縣市，就移到 ADDRESS\n",
    "    location_as_address = {\"台北市\", \"新北市\", \"台中市\", \"台南市\", \"高雄市\", \"桃園市\", \"宜蘭縣\", \"新竹市\"}\n",
    "    for loc in result[\"LOCATION\"][:]:\n",
    "        if loc in location_as_address:\n",
    "            result[\"LOCATION\"].remove(loc)\n",
    "            result[\"ADDRESS\"].append(loc)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def classify_query_type(query, query_model, query_tokenizer):\n",
    "    \"\"\"使用 mT5 模型來分類 Query 類型（geo_filter / geo_distance）\"\"\"\n",
    "    input_ids = query_tokenizer(query, return_tensors=\"pt\").input_ids.to(query_model.device)\n",
    "    outputs = query_model.generate(input_ids, max_length=10, num_return_sequences=1, do_sample=False)\n",
    "    result = query_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    if result not in [\"geo_filter\", \"geo_distance\"]:\n",
    "        result = \"geo_filter\"  # 預設為 geo_filter\n",
    "    \n",
    "    return {\"search_type\": [result]}\n",
    "\n",
    "def nlu_pipeline(query):\n",
    "    \"\"\"完整 NLU 流程：NER + Query 類型分類\"\"\"\n",
    "    ner_pipeline, query_model, query_tokenizer = load_nlu_models()\n",
    "    \n",
    "    entities = extract_entities(query, ner_pipeline)\n",
    "    query_type = classify_query_type(query, query_model, query_tokenizer)\n",
    "    \n",
    "    return {**entities, **query_type}\n",
    "\n",
    "# 測試\n",
    "query = \"阿里山有哪些咖啡館？\"\n",
    "result = nlu_pipeline(query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 效果尚可，還有進步空間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOCATION': ['SunMoonLake'], 'ADDRESS': [], 'POI_TYPE': ['餐廳'], 'NEED': [], 'search_type': ['unknown']}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_nlu_models():\n",
    "    \"\"\"載入 NER（XLM-RoBERTa）與 Query 分類（mT5）模型\"\"\"\n",
    "    # NER 模型（XLM-RoBERTa，使用新模型 Davlan/xlm-roberta-base-ner-hrl）\n",
    "    ner_model_name = \"Davlan/xlm-roberta-base-ner-hrl\"\n",
    "    ner_tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_name)\n",
    "    ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    # Query 類別分類（mT5）\n",
    "    query_model_name = \"google/mt5-small\"\n",
    "    query_tokenizer = T5Tokenizer.from_pretrained(query_model_name, model_max_length=512)\n",
    "    query_model = MT5ForConditionalGeneration.from_pretrained(query_model_name, device_map=\"auto\")\n",
    "    \n",
    "    return ner_pipeline, query_model, query_tokenizer\n",
    "\n",
    "# 初始化語意向量模型\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# 定義 POI 類型關鍵字\n",
    "POI_KEYWORDS = [\n",
    "    \"餐廳\", \"中餐館\", \"亞洲菜餐廳\", \"火鍋餐廳\", \"夜市\", \"甜品店\", \"冰品飲料店\", \"美食廣場\",\n",
    "    \"咖啡館\", \"茶葉店\", \"茶市\", \"茶批發商\", \"茶製造商\", \"酒品專賣店\", \"釀酒廠\", \"酒樓\", \"飯盒供應商\",\n",
    "    \"酒店\", \"賓館\", \"旅館\", \"民宿\", \"渡假村\", \"長期住宿酒店\", \"宗教住宿場所\",\n",
    "    \"旅遊景點\", \"觀光牧場\", \"觀光農場\", \"自然保護區\", \"國家公園\", \"國家森林\", \"水上樂園\", \"海濱長廊\", \"沙灘\",\n",
    "    \"湖泊\", \"河流\", \"島嶼\", \"山峰\", \"遺址博物館\", \"歷史景點\", \"文化地標\", \"紀念公園\", \"紀念碑\",\n",
    "    \"登山纜車\", \"行山徑\", \"溫泉\", \"露營地點\", \"釣魚池\",\"公園\",\n",
    "    \"博物館\", \"歷史博物館\", \"科學館\", \"藝術博物館\", \"手工藝博物館\", \"動物學博物館\", \"海事博物館\",\n",
    "    \"音樂廳\", \"歌劇院\", \"演藝劇場\", \"展覽場地\", \"展覽貿易中心\", \"藝術中心\", \"文化中心\",\n",
    "    \"百貨公司\", \"購物中心\", \"市場\", \"農產品市場\", \"海鮮市場\", \"紀念品商店\", \"禮品店\", \"書店\", \"古董店\",\n",
    "    \"寺廟\", \"天主教教堂\", \"神社\", \"道觀\", \"宗教聖地\", \"神壇\",\n",
    "    \"火車站\", \"渡輪碼頭\", \"機票代理公司\", \"橋樑\", \"隧道\", \"鐵路公司\", \"鐵道服務\", \"停車場\",\n",
    "    \"遊樂場\", \"主題公園\", \"摩天輪\", \"動物園\", \"野生動物園\", \"體育館\", \"漆彈射擊場\", \"潛水中心\", \"單車徑\"\n",
    "]\n",
    "\n",
    "# 預計算 POI 關鍵字向量\n",
    "poi_embeddings = embedding_model.encode(POI_KEYWORDS, convert_to_numpy=True)\n",
    "faiss_index = faiss.IndexFlatL2(poi_embeddings.shape[1])\n",
    "faiss_index.add(poi_embeddings)\n",
    "\n",
    "def detect_poi_type(query):\n",
    "    \"\"\"使用語意向量檢索 POI_TYPE，選擇最符合的類別\"\"\"\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    D, I = faiss_index.search(query_embedding, 3)  # 取最相近的 3 個 POI 類型\n",
    "    \n",
    "    # 過濾：優先選擇較廣泛的 POI 類型\n",
    "    preferred_types = {\"餐廳\", \"美食廣場\", \"夜市\", \"旅遊景點\", \"市場\"}\n",
    "    for idx in I[0]:\n",
    "        if idx >= 0 and POI_KEYWORDS[idx] in preferred_types:\n",
    "            return [POI_KEYWORDS[idx]]\n",
    "    \n",
    "    # 若找不到適合的廣泛類型，則回傳最相似的結果\n",
    "    return [POI_KEYWORDS[I[0][0]]] if I[0][0] >= 0 else []\n",
    "\n",
    "def nlu_pipeline(query):\n",
    "    \"\"\"完整 NLU 流程：NER + Query 類型分類 + POI_TYPE 語意檢索\"\"\"\n",
    "    ner_pipeline, query_model, query_tokenizer = load_nlu_models()\n",
    "    \n",
    "    entities = extract_entities(query, ner_pipeline)\n",
    "    query_type = classify_query_type(query, query_model, query_tokenizer)\n",
    "    \n",
    "    # **使用語意檢索 POI_TYPE**\n",
    "    if not entities[\"POI_TYPE\"]:  \n",
    "        entities[\"POI_TYPE\"] = detect_poi_type(query)\n",
    "    \n",
    "    return {**entities, **query_type}\n",
    "\n",
    "# 測試\n",
    "query = \"I'm looking for a takeaway restaurant or snack near Sun Moon Lake\"\n",
    "result = nlu_pipeline(query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  嘗試訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [565/565 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.342694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.695917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.318912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.222490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10.493400</td>\n",
       "      <td>0.885306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled mT5 訓練完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOCATION': ['SunMoonLake'], 'ADDRESS': [], 'POI_TYPE': ['餐廳'], 'NEED': [], 'search_type': ['geo_filter']}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "def load_nlu_models():\n",
    "    \"\"\"載入 NER（XLM-RoBERTa）與 Query 分類（Distil-mT5）模型\"\"\"\n",
    "    # NER 模型（XLM-RoBERTa）\n",
    "    ner_model_name = \"Davlan/xlm-roberta-base-ner-hrl\"\n",
    "    ner_tokenizer = AutoTokenizer.from_pretrained(ner_model_name)\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_name)\n",
    "    ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    # Query 類別分類（Distil-mT5）\n",
    "    query_model_name = \"google/mt5-small\"\n",
    "    query_tokenizer = T5Tokenizer.from_pretrained(query_model_name, model_max_length=128)\n",
    "    query_model = MT5ForConditionalGeneration.from_pretrained(query_model_name, device_map=\"auto\")\n",
    "    \n",
    "    return ner_pipeline, query_model, query_tokenizer\n",
    "\n",
    "# 初始化語意向量模型\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "def load_training_data(file_path, tokenizer):\n",
    "    \"\"\"從 CSV 文件載入訓練數據，並對 Query 進行 Tokenization\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 轉換文字標籤（geo_filter / geo_distance）為 Token 格式\n",
    "    label_texts = df[\"label\"].tolist()\n",
    "    tokenized_labels = tokenizer(label_texts, padding=True, truncation=True, max_length=10, return_tensors=\"pt\")\n",
    "    \n",
    "    # 對 Query 進行 Tokenization\n",
    "    tokenized_data = tokenizer(df[\"query\"].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    \n",
    "    # 建立 Dataset 格式\n",
    "    dataset = datasets.Dataset.from_dict({\n",
    "        \"input_ids\": tokenized_data[\"input_ids\"].tolist(),\n",
    "        \"attention_mask\": tokenized_data[\"attention_mask\"].tolist(),\n",
    "        \"labels\": tokenized_labels[\"input_ids\"].tolist()\n",
    "    })\n",
    "    \n",
    "    return dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "training_file_path = \"geo_training_data.csv\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "data_splits = load_training_data(training_file_path, tokenizer)\n",
    "train_data = data_splits[\"train\"]\n",
    "eval_data = data_splits[\"test\"]\n",
    "\n",
    "def train_distilled_mt5():\n",
    "    \"\"\"訓練 Distil-mT5 進行 `geo_filter` vs `geo_distance` 分類\"\"\"\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=\"./distilled_mt5\", per_device_train_batch_size=8, num_train_epochs=5,\n",
    "        logging_dir=\"./logs\", save_steps=500, evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5, weight_decay=0.01, save_total_limit=2\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\"))\n",
    "    trainer = Trainer(\n",
    "        model=MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\"),\n",
    "        args=train_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=eval_data,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.save_model(\"./distilled_mt5\")\n",
    "    print(\"Distilled mT5 訓練完成\")\n",
    "\n",
    "train_distilled_mt5()\n",
    "\n",
    "# 測試\n",
    "query = \"I'm looking for a takeaway restaurant or snack near Sun Moon Lake\"\n",
    "result = nlu_pipeline(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "tokenizer.save_pretrained(\"./distilled_mt5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_type': ['unknown']}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "def classify_query_type(query, query_model, query_tokenizer):\n",
    "    \"\"\"使用 `distilled_mt5` 進行查詢類別分類\"\"\"\n",
    "    input_ids = query_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).input_ids.to(query_model.device)\n",
    "    \n",
    "    \n",
    "    outputs = query_model.generate(\n",
    "        input_ids, \n",
    "        max_length=20, \n",
    "        num_return_sequences=1,\n",
    "        do_sample=False,   \n",
    "        num_beams=5        \n",
    "    )\n",
    "    \n",
    "    result = query_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "    \n",
    "    if result.startswith(\"<extra_id_\") or result == \"\":\n",
    "        result = \"unknown\"\n",
    "    \n",
    "    return {\"search_type\": [result]}\n",
    "\n",
    "# 測試 `distilled_mt5`\n",
    "query = \"I'm looking for a takeaway restaurant or snack near Sun Moon Lake\"\n",
    "result = classify_query_type(query, query_model, query_tokenizer)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'es_query': '<extra_id_0>_distance'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "def load_trained_mt5():\n",
    "    \"\"\"載入已訓練的 Distilled mT5\"\"\"\n",
    "    query_model_name = \"./distilled_mt5\"  \n",
    "    query_tokenizer = T5Tokenizer.from_pretrained(query_model_name)\n",
    "    query_model = MT5ForConditionalGeneration.from_pretrained(query_model_name, device_map=\"auto\")\n",
    "    return query_model, query_tokenizer\n",
    "\n",
    "def generate_es_query(query_model, query_tokenizer, location, poi_type, need, distance):\n",
    "    \"\"\"用 mT5 產生 Elasticsearch Query DSL\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    請根據以下條件生成 Elasticsearch Query：\n",
    "    地點：「{location}」\n",
    "    類別：「{poi_type}」\n",
    "    需求：「{need}」\n",
    "    搜尋範圍：「{distance} 內」\n",
    "    請輸出符合 Elasticsearch DSL 格式的 JSON 查詢語句：\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = query_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).input_ids.to(query_model.device)\n",
    "    outputs = query_model.generate(input_ids, max_length=256)\n",
    "    result = query_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return {\"es_query\": result}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #  載入模型\n",
    "    query_model, query_tokenizer = load_trained_mt5()\n",
    "    \n",
    "    #  測試 Elasticsearch Query 生成\n",
    "    test_query = generate_es_query(query_model, query_tokenizer, \"台北101\", \"餐廳\", \"景觀\", \"5km\")\n",
    "    print(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'es_query': '<extra_id_0>:'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "def generate_es_query(query_model, query_tokenizer, location, poi_type, need, distance):\n",
    "    \"\"\"用 mT5 產生 Elasticsearch Query DSL\"\"\"\n",
    "    \n",
    "    # 讓 mT5 學會 JSON 結構\n",
    "    example_query = \"\"\"\n",
    "    請根據以下條件生成 Elasticsearch Query：\n",
    "    地點：「阿里山」\n",
    "    類別：「咖啡館」\n",
    "    需求：「景觀」\n",
    "    搜尋範圍：「5km 內」\n",
    "    輸出：\n",
    "    {\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            { \"match\": { \"gmap_location\": \"阿里山\" } },\n",
    "            { \"match\": { \"class\": \"咖啡館\" } }\n",
    "          ],\n",
    "          \"filter\": [\n",
    "            { \"geo_distance\": { \"distance\": \"5km\", \"gmap_coordinates\": { \"lat\": 23.508, \"lon\": 120.802 } } }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    {example_query}\n",
    "    現在請根據以下條件生成 Elasticsearch Query：\n",
    "    地點：「{location}」\n",
    "    類別：「{poi_type}」\n",
    "    需求：「{need}」\n",
    "    搜尋範圍：「{distance} 內」\n",
    "    輸出：\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = query_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).input_ids.to(query_model.device)\n",
    "    outputs = query_model.generate(input_ids, max_length=256)\n",
    "    result = query_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return {\"es_query\": result}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #  載入模型（改用 `google/mt5-small`）\n",
    "    query_model, query_tokenizer = load_mt5()\n",
    "    \n",
    "    #  測試 Elasticsearch Query 生成\n",
    "    test_query = generate_es_query(query_model, query_tokenizer, \"台北101\", \"餐廳\", \"景觀\", \"5km\")\n",
    "    print(test_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嘗試Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 產生的 Elasticsearch Query:\n",
      " ```json\n",
      "{\n",
      "  \"query\": {\n",
      "    \"bool\": {\n",
      "      \"must\": [\n",
      "        {\n",
      "          \"match\": {\n",
      "            \"class\": \"咖啡廳\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"filter\": [\n",
      "        {\n",
      "          \"geo_distance\": {\n",
      "            \"distance\": \"5km\",  // 可調整距離\n",
      "            \"gmap_coordinates\": {\n",
      "              \"lat\": 23.500754,  // 阿里山的緯度，需要實際查詢\n",
      "              \"lon\": 120.802632   // 阿里山的經度，需要實際查詢\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**說明:**\n",
      "\n",
      "1. **`query` - `bool` - `must`**:  使用 `match` 查詢 `class` 欄位，確保結果包含 \"咖啡廳\"。\n",
      "2. **`query` - `bool` - `filter`**: 使用 `geo_distance` 篩選器，根據提供的阿里山經緯度座標，查找附近的結果。`distance` 設定為 \"5km\"，可以根據需要調整搜索半徑。**注意：阿里山的經緯度需要替換成實際的經緯度值。**  使用 `filter` context 確保效能，因為 `filter` 不計算分數。\n",
      "3. **`filter` 為 list 格式**: 符合題目要求，即使只有一個 filter 也使用 list 包裹。\n",
      "\n",
      "\n",
      "**使用方法:**\n",
      "\n",
      "1. 將阿里山的經緯度替換成正確的值。\n",
      "2. 將 JSON 查詢語句複製到 Elasticsearch 的搜尋 API 中執行。\n",
      "3. 調整 `distance` 參數以控制搜索半徑。\n",
      "\n",
      "\n",
      "**額外說明:**\n",
      "\n",
      "* 如果需要更精確的「附近」定義，可以考慮使用更小的 `distance` 值。\n",
      "* 可以根據需求添加其他 `must` 或 `filter` 條件，例如根據 `tags` 篩選「適合兒童」的咖啡廳。\n",
      "*  如果沒有阿里山的精確經緯度，可以使用 `gmap_location` 欄位搭配 `match` 查詢，先找到阿里山的地點，再提取其經緯度座標進行 `geo_distance` 查詢。  但這種方法的效能不如直接使用經緯度。\n",
      "\n",
      "\n",
      "這個解答提供了一個基本的框架，您可以根據實際需求進行調整和擴展。\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "# 設定你的 Gemini API Key\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "def generate_es_query_gemini(query):\n",
    "    \"\"\"使用 Gemini 產生符合 Elasticsearch Mapping 的 Query，確保 `filter` 是陣列\"\"\"\n",
    "    schema_info = \"\"\"\n",
    "    你的 Elasticsearch 資料結構如下：\n",
    "    - `gmap_location`: 地點名稱 (如 \"台北101\")\n",
    "    - `location_ID`: Google 地點 ID\n",
    "    - `class`: 地點類型 (如 \"餐廳\", \"咖啡館\", \"旅遊景點\")\n",
    "    - `address`: 地址\n",
    "    - `summary_1`: 簡介\n",
    "    - `tags`: 標籤 (如 \"適合兒童\", \"景觀優美\", \"無障礙設施\")\n",
    "    - `gmap_coordinates`: 經緯度座標 (lat, lon)\n",
    "\n",
    "    **請確保生成的 Elasticsearch Query 只包含這些欄位，且 `filter` 必須是 `list` 格式。**\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    {schema_info}\n",
    "    請將以下自然語言查詢轉換為符合 Elasticsearch JSON Query DSL：\n",
    "    查詢：「{query}」\n",
    "    生成符合 JSON 格式的 Elasticsearch 查詢語句，**請確保 `filter` 是 `list` 格式**：\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")  # 使用 Gemini 1.5 Pro\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# 測試\n",
    "query = \"我想找阿里山附近的咖啡廳？\"\n",
    "es_query = generate_es_query_gemini(query)\n",
    "print(\"🔍 產生的 Elasticsearch Query:\\n\", es_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# 設定Gemini API Key\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "# 設定全域變數，統一使用 Gemini 模型\n",
    "GEMINI_MODEL = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "# 連接 Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "INDEX_NAME = \"gmap_location\"  \n",
    "\n",
    "def find_location_in_database(query):\n",
    "    \"\"\"查詢地點是否存在於 Elasticsearch，返回經緯度或 None\"\"\"\n",
    "    search_body = {\n",
    "        \"query\": {\n",
    "            \"match_phrase\": {\"gmap_location\": query}\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index=INDEX_NAME, body=search_body)\n",
    "    \n",
    "    if response[\"hits\"][\"total\"][\"value\"] > 0:\n",
    "        location_data = response[\"hits\"][\"hits\"][0][\"_source\"]\n",
    "        return {\n",
    "            \"gmap_location\": location_data[\"gmap_location\"],\n",
    "            \"gmap_coordinates\": location_data[\"gmap_coordinates\"]\n",
    "        }\n",
    "    return \"None\"\n",
    "\n",
    "def generate_es_query_gemini(query):\n",
    "    \"\"\"綜合流程，產生 Elasticsearch Query，並執行查詢\"\"\"\n",
    "    location_data = find_location_in_database(query)\n",
    "    \n",
    "    if location_data == \"None\":\n",
    "        raise ValueError(\"無法找到地點，請檢查查詢內容！\")\n",
    "    \n",
    "    center_point = location_data.get(\"gmap_coordinates\", None)\n",
    "    if center_point is None:\n",
    "        raise ValueError(\"回傳的地點缺少 `gmap_coordinates`，檢查 API 回應\")\n",
    "    \n",
    "    search_type = \"geo_distance\" \n",
    "    \n",
    "    schema_info = \"\"\"\n",
    "    Elasticsearch Index 結構如下：\n",
    "    - `gmap_location`: 地點名稱 (如 \"台北101\")\n",
    "    - `class`: 地點類型 (如 \"餐廳\", \"咖啡館\", \"旅遊景點\")\n",
    "    - `gmap_coordinates`: 經緯度座標 (lat, lon)\n",
    "    **請確保生成的 Elasticsearch Query 只包含這些欄位，並符合 JSON 格式。**\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {schema_info}\n",
    "    請根據以下條件生成 Elasticsearch Query：\n",
    "    - 地點：「{query}」\n",
    "    - 查詢類型：「{search_type}」\n",
    "    - 參考經緯度：「{center_point}」\n",
    "    - 搜尋範圍：「1km」\n",
    "    **請輸出完整的 JSON 查詢語句，不要額外解釋。**\n",
    "    \"\"\"\n",
    "    response = GEMINI_MODEL.generate_content(prompt)\n",
    "    es_query = response.text.strip()\n",
    "    \n",
    "    # 執行 Elasticsearch 查詢\n",
    "    try:\n",
    "        es_response = es.search(index=INDEX_NAME, body=json.loads(es_query))\n",
    "        return es_response[\"hits\"][\"hits\"]\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"JSON 解析錯誤，Gemini 回傳內容無法解析:\\n{es_query}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"阿里山有哪些咖啡館？\"\n",
    "    try:\n",
    "        results = generate_es_query_gemini(query)\n",
    "        print(\"Elasticsearch 查詢結果:\")\n",
    "        for result in results:\n",
    "            print(result[\"_source\"])\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: I would like find the nearest museum of Shilin Night Market\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"gmap_location\": \"士林夜市\",\n",
      "  \"class\": \"博物館\",\n",
      "  \"geo_distance\": \"附近\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Gemini API Key\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "# 設定全域變數，使用 Gemini 模型\n",
    "GEMINI_MODEL = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "\n",
    "def parse_query_with_gemini(query, chat):\n",
    "    \"\"\"讓 Gemini 解析 Query 並輸出結構化 JSON\"\"\"\n",
    "    prompt = f\"\"\"    \n",
    "    做為NLP解析器，以及台灣的旅遊專家，解析以下使用者查詢，並輸出標籤與內容：\n",
    "    \n",
    "    **標籤**：\n",
    "    - `gmap_location`: 確切地點名稱\n",
    "    - `address`: 地址\n",
    "    - `class`: google map上的地點類型\n",
    "    - `opening_hours`: 營業時間\n",
    "    - `entrance_fee`: 門票、免費等\n",
    "    - `tags`: google map的地點標籤，如\"適合兒童\"、\"無障礙停車場\"、\"洗手間\"、Wi-Fi\"\n",
    "    - `geo_distance`: 地理距離搜尋的半徑，如\"1公里\"、\"附近\"\n",
    "    - `semantic_keywords`: 語意關鍵詞(用於語意檢索)、其他不屬於上述資料結構的詞，或是任何可能在google map評論出現的詞，如\"安靜的\"、\"海邊看夕陽\"\n",
    "      \n",
    "     \n",
    "    \n",
    "    以下是一些解析範例：\n",
    "\n",
    "    query：「南港適合小孩子的博物館，有無障礙停車場」 \n",
    "    輸出：\n",
    "        \"address\": \"南港區\",        \n",
    "        \"class\": \"博物館\",\n",
    "        \"tags\": [\"無障礙停車場\",\"適合兒童\"]\n",
    "    \n",
    "    query：「推薦國父紀念館5公里內的咖啡店，週二下午有開的」\n",
    "    輸出：\n",
    "        \"gmap_location\": \"國父紀念館\",        \n",
    "        \"class\": \"咖啡館\",\n",
    "        \"geo_distance\": \"5km\",\n",
    "        \"opening_hours\":[\"週二\",\"下午\"]\n",
    "    \n",
    "    query：「大安和信義區有哪些免費的美術館，要有現代設計的展覽內容」\n",
    "    輸出：\n",
    "        \"address\": \"大安區\",\"信義區\"        \n",
    "        \"class\": \"藝術博物館\",\"現代藝術博物館\"\n",
    "        \"entrance_fee\": \"free\",\n",
    "        \"semantic_keywords\":[\"現代\",\"設計\"]\n",
    "\n",
    "    query：「推薦一間台東靠海邊安靜的餐廳」\n",
    "    輸出：\n",
    "        \"address\": \"台東縣\",\"台東市\"        \n",
    "        \"class\": \"餐廳\",        \n",
    "        \"semantic_keywords\":[\"安靜\",\"靠海\",\"海邊\"]\n",
    "    \n",
    "    **台灣所有的縣市都要解析為address，如台中=台中市、新竹=\"新竹縣\"、\"新竹市\"**\n",
    "    **\"gmap_location\"和\"address\"不同時出現在同一輸出，沒有明確地點才選擇\"address\"\n",
    "    **class要對應google map上的地點類型**\n",
    "    **如果有對距離的描述，如\"附近\"、\"周邊\"請使用\"geo_distance\": \"5km\"**\n",
    "    *輸入外文要轉換成中文，除了\"semantic_keywords\"保留原文*\n",
    "\n",
    "    請將以下查詢解析\n",
    "    「{query}」\n",
    "\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # response = GEMINI_MODEL.generate_content(prompt)\n",
    "    response = chat.send_message(prompt)\n",
    "    \n",
    "   # 判斷是否成功回傳\n",
    "    if response.parts:\n",
    "        try:\n",
    "            parsed_query = json.loads(response.text.strip())\n",
    "            return parsed_query\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(f\"\\n{response.text.strip()}\")\n",
    "    else:\n",
    "        raise ValueError(f\"回傳失敗\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 建立新的對話\n",
    "    chat = GEMINI_MODEL.start_chat()\n",
    "\n",
    "    # 測試不同的查詢語句\n",
    "    queries = [        \n",
    "        \"I would like find the nearest museum of Shilin Night Market\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        try:\n",
    "            result = parse_query_with_gemini(query, chat)\n",
    "            print(\"解析結果:\")\n",
    "            print(json.dumps(result, ensure_ascii=False, indent=2))\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "        time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query: 台北市有哪些免費的博物館？\n",
    "{\"address\": \"台北市\",\"class\": \"博物館\",\"entrance_fee\": \"免費\"}\n",
    "\n",
    "Query: 哪裡有適合親子的公園？\n",
    "{\"class\": \"公園\",\"tags\": \"適合兒童\"}\n",
    "\n",
    "Query: 我想找陽明山的咖啡館\n",
    "{\"location\": \"陽明山\",\"type\":\"gmap_location\",\"class\": \"咖啡館\"}\n",
    "\n",
    "Query: 我想找信義區 1 公里內的夜市\n",
    "{\"location\": \"信義區\",\"type\": \"address\",\"class\": \"夜市\",\"geo_distance\": 1km\"}\n",
    "\n",
    "Query: 推薦一個安靜的餐廳\n",
    "{\"class\": \"餐廳\",\"semantic_keywords\":['安靜']}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
